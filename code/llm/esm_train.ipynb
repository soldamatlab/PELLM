{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNG<mask><mask><mask>EWTYDDATKTFT<mask>TE\"]\n",
    "variants = [\"<mask><mask><mask><mask>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet.mask_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.sequences[idx]\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sequences = torch.tensor([[6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11]])\n",
    "dataset = SequenceDataset(sequences)\n",
    "dataloader = DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "batches = [b for b in dataloader]\n",
    "batch = batches[0]\n",
    "batch\n",
    "\n",
    "input = batch.clone()\n",
    "input[:, 3] = alphabet.mask_idx\n",
    "logits = model(input)['logits']\n",
    "logits = logits.view(-1, len(alphabet.all_toks))\n",
    "loss = loss_function(logits, batch.view(-1))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 17.2130, -10.4268,   4.3073, -10.3417,  -5.0231,  -5.5713,  -5.3020,\n",
       "          -6.2960,  -6.6767,  -7.1270,  -7.2446,  -6.9955,  -4.9150,  -4.8448,\n",
       "          -4.8673,  -7.4093,  -7.5647,  -6.7933,  -4.7558,  -6.4050,  -4.1163,\n",
       "          -6.4284,  -6.9402,  -5.1816, -16.4025,  -8.9111,  -5.1899,  -6.8634,\n",
       "         -15.3043, -15.1924, -14.0209, -15.4579, -10.3194],\n",
       "        [-14.2885, -17.6840, -10.2384, -17.5906,  -0.5864,  -0.6038,  -1.0612,\n",
       "           2.2265,  -0.4483,  -1.4295,  -0.6930,  -1.0180,  -1.5467,  -1.6886,\n",
       "          -0.9941,  -1.7375,  -1.8032,  -2.0228,  -1.7846,  -2.1204,   1.0479,\n",
       "          -2.2927,  -2.4638,  -1.7659,  -2.8254,  -9.7229, -11.3728, -11.1799,\n",
       "         -16.4022, -16.2923, -16.1494, -16.4295, -17.6588],\n",
       "        [-14.8074, -17.2731,  -9.4569, -17.2336,  -0.3289,  -0.1936,  -0.4727,\n",
       "          -0.5211,   3.0008,  -0.8466,  -0.1246,  -0.6098,  -0.9388,  -1.2826,\n",
       "          -0.6558,  -0.8636,  -1.1136,  -1.2914,  -1.3697,  -1.6351,  -1.9211,\n",
       "          -1.5124,  -1.7556,  -1.5701,  -5.5121, -11.0140, -12.7751, -11.7606,\n",
       "         -16.4550, -16.5153, -16.4731, -16.7538, -17.2993],\n",
       "        [-15.2203, -17.6207, -11.0490, -17.6222,   0.3909,   0.3304,   0.3682,\n",
       "           0.1150,   0.7655,  -0.2828,   0.7598,   0.2130,  -0.2721,  -0.5650,\n",
       "           0.0733,  -0.2512,  -0.5014,  -0.6072,  -0.5630,  -0.9796,  -1.1224,\n",
       "          -0.7985,  -0.8024,  -0.5325,  -4.8433, -10.7978, -12.7403, -11.9425,\n",
       "         -16.4358, -16.5236, -16.5619, -16.6817, -17.6215],\n",
       "        [-13.9664, -18.2775, -10.7754, -18.2582,  -0.3417,  -0.4075,  -0.5535,\n",
       "          -0.6109,  -0.0635,  -1.0077,   3.1225,  -0.5695,  -0.9241,  -1.3052,\n",
       "          -0.7364,  -0.8451,  -1.2519,  -1.2948,  -1.2332,  -1.6638,  -1.8802,\n",
       "          -1.5787,  -1.7175,  -1.5086,  -5.0433, -10.8778, -12.5503, -11.6315,\n",
       "         -16.4127, -16.3837, -16.3729, -16.6578, -18.3271],\n",
       "        [ -8.0859, -14.5180,  23.9712, -14.7900,  -0.9623,   0.2108,  -0.5531,\n",
       "          -1.0370,  -0.8200,  -1.5114,  -0.6367,  -1.2854,  -2.0014,  -1.2409,\n",
       "          -2.0100,  -0.6788,  -1.6075,  -1.5812,  -1.8260,  -2.0544,  -0.1792,\n",
       "          -2.7483,  -1.1757,  -1.5756,  -3.6189,  -8.3660,  -9.5731,  -8.7212,\n",
       "         -15.2025, -15.8152, -15.2997, -16.1584, -14.8657],\n",
       "        [ 17.2130, -10.4268,   4.3073, -10.3417,  -5.0231,  -5.5713,  -5.3020,\n",
       "          -6.2960,  -6.6767,  -7.1270,  -7.2446,  -6.9955,  -4.9150,  -4.8448,\n",
       "          -4.8673,  -7.4093,  -7.5647,  -6.7933,  -4.7558,  -6.4050,  -4.1163,\n",
       "          -6.4284,  -6.9402,  -5.1816, -16.4025,  -8.9111,  -5.1899,  -6.8634,\n",
       "         -15.3043, -15.1924, -14.0209, -15.4579, -10.3194],\n",
       "        [-14.2885, -17.6840, -10.2384, -17.5906,  -0.5864,  -0.6038,  -1.0612,\n",
       "           2.2265,  -0.4483,  -1.4295,  -0.6930,  -1.0180,  -1.5467,  -1.6886,\n",
       "          -0.9941,  -1.7375,  -1.8032,  -2.0228,  -1.7846,  -2.1204,   1.0479,\n",
       "          -2.2927,  -2.4638,  -1.7659,  -2.8254,  -9.7229, -11.3728, -11.1799,\n",
       "         -16.4022, -16.2923, -16.1494, -16.4295, -17.6588],\n",
       "        [-14.8074, -17.2731,  -9.4569, -17.2336,  -0.3289,  -0.1936,  -0.4727,\n",
       "          -0.5211,   3.0008,  -0.8466,  -0.1246,  -0.6098,  -0.9388,  -1.2826,\n",
       "          -0.6558,  -0.8636,  -1.1136,  -1.2914,  -1.3697,  -1.6351,  -1.9211,\n",
       "          -1.5124,  -1.7556,  -1.5701,  -5.5121, -11.0140, -12.7751, -11.7606,\n",
       "         -16.4550, -16.5153, -16.4731, -16.7538, -17.2993],\n",
       "        [-15.2203, -17.6207, -11.0490, -17.6222,   0.3909,   0.3304,   0.3682,\n",
       "           0.1150,   0.7655,  -0.2828,   0.7598,   0.2130,  -0.2721,  -0.5650,\n",
       "           0.0733,  -0.2512,  -0.5014,  -0.6072,  -0.5630,  -0.9796,  -1.1224,\n",
       "          -0.7985,  -0.8024,  -0.5325,  -4.8433, -10.7978, -12.7403, -11.9425,\n",
       "         -16.4358, -16.5236, -16.5619, -16.6817, -17.6215],\n",
       "        [-13.9664, -18.2775, -10.7754, -18.2582,  -0.3417,  -0.4075,  -0.5535,\n",
       "          -0.6109,  -0.0635,  -1.0077,   3.1225,  -0.5695,  -0.9241,  -1.3052,\n",
       "          -0.7364,  -0.8451,  -1.2519,  -1.2948,  -1.2332,  -1.6638,  -1.8802,\n",
       "          -1.5787,  -1.7175,  -1.5086,  -5.0433, -10.8778, -12.5503, -11.6315,\n",
       "         -16.4127, -16.3837, -16.3729, -16.6578, -18.3271],\n",
       "        [ -8.0859, -14.5180,  23.9712, -14.7900,  -0.9623,   0.2108,  -0.5531,\n",
       "          -1.0370,  -0.8200,  -1.5114,  -0.6367,  -1.2854,  -2.0014,  -1.2409,\n",
       "          -2.0100,  -0.6788,  -1.6075,  -1.5812,  -1.8260,  -2.0544,  -0.1792,\n",
       "          -2.7483,  -1.1757,  -1.5756,  -3.6189,  -8.3660,  -9.5731,  -8.7212,\n",
       "         -15.2025, -15.8152, -15.2997, -16.1584, -14.8657]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7067, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 33])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['logits'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 33])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = out['logits']\n",
    "logits = logits.view(-1, len(alphabet.all_toks))\n",
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.5965, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "loss_function(logits, sequences.view(-1))\n",
    "#loss(torch.logit(torch.tensor([[0.98, 0.01, 0.01], [0.01, 0.98, 0.01]])), torch.tensor([0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 3, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[0, 0, 0, 0], [1, 1, 1, 1], [0, 0, 0, 0]], [[0, 0, 3, 0], [1, 1, 1, 1], [0, 0, 0, 0]]])\n",
    "a = a.view(-1, 4)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
