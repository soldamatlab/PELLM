{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "#from lib.model.progen.init_model import init_model\n",
    "from lib.model.extended.init_model import init_model\n",
    "from lib.model.train import train\n",
    "from lib.model.progen.init_tokenizer import init_tokenizer\n",
    "from lib.data.datasets.GB1 import get_GB1_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = init_tokenizer()\n",
    "tokenize = lambda sequence: torch.tensor(tokenizer.encode(sequence).ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s:\\Documents\\master\\code\\llm\\lib\\model\\progen/../../../../../ProGen/progen/progen2/checkpoints/progen2-small were not used when initializing ProGenModel: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing ProGenModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ProGenModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model state dict from file \"s:\\Documents\\master\\code\\llm/models/progen_extended_data_filter_01.pt\"\n"
     ]
    }
   ],
   "source": [
    "#model = init_model().to(device)\n",
    "#model = init_model(state_dict_path=\"/models/progen_extended_data_balanced_01.pt\").to(device)\n",
    "model = init_model(state_dict_path=\"/models/progen_extended_data_filter_01.pt\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([param for param in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0345, device='cuda:0', grad_fn=<UnbindBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(abs(model.fitness_head.weight[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained model sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Documents\\master\\code\\llm\\lib\\data\\datasets\\GB1.py:144: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized[s, :] = torch.tensor(tokenize(sequences[s]))\n",
      "Some weights of the model checkpoint at s:\\Documents\\master\\code\\llm\\lib\\model\\progen/../../../../../ProGen/progen/progen2/checkpoints/progen2-small were not used when initializing ProGenModel: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing ProGenModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ProGenModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model state dict from file \"s:\\Documents\\master\\code\\llm/models/progen_extended_data_balanced_01.pt\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerExtended(\n",
       "  (transformer): ProGenModel(\n",
       "    (wte): Embedding(32, 1024)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fitness_head): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (activation_function): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from lib.model.extended.init_model import init_model\n",
    "from lib.model.progen.init_tokenizer import init_tokenizer\n",
    "from lib.data.datasets.GB1 import prepare_sequences, tokenize_batch, load_data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = init_tokenizer()\n",
    "tokenize = lambda sequence: torch.tensor(tokenizer.encode(sequence).ids)\n",
    "\n",
    "info = torch.load(\"./models/progen_extended_data_balanced_01_info.pt\")\n",
    "test_variants = info[\"test_variants\"]\n",
    "test_sequences = tokenize_batch(prepare_sequences(test_variants), tokenize).to(device)\n",
    "#df = load_data()\n",
    "\n",
    "model = init_model(state_dict_path=\"/models/progen_extended_data_balanced_01.pt\").to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_df = df.loc[df[\"Variants\"].isin(test_variants)]\n",
    "best_test_variant = np.argmax(test_df[\"Fitness\"].values)\n",
    "best_test_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0034], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "[2.54879988]\n"
     ]
    }
   ],
   "source": [
    "sequence_id = best_test_variant\n",
    "\n",
    "print(model(test_sequences[sequence_id])[-1])\n",
    "print(df.loc[df[\"Variants\"] == test_variants[sequence_id]][\"Fitness\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save / Load model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.getcwd() + \"/models/progen_extended_v1.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, MODEL_PATH)\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load(MODEL_PATH)\n",
    "\n",
    "# ! init the model first\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "tokenize = lambda sequence: tokenizer.encode(sequence).ids\n",
    "\n",
    "sequences, fitnesses = get_GB1_dataset(\n",
    "    tokenize=tokenize,\n",
    "    device=device,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "TEST_SPLIT = 500 / 149631\n",
    "\n",
    "tokenize = lambda sequence: tokenizer.encode(sequence).ids\n",
    "\n",
    "train_sequences, train_fitnesses, test_sequences, test_fitnesses = get_GB1_dataset(\n",
    "    tokenize=tokenize,\n",
    "    test_split=TEST_SPLIT,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DATA = 100\n",
    "\n",
    "n_train = int(N_DATA * (1-TEST_SPLIT))\n",
    "n_test = int(N_DATA * TEST_SPLIT)\n",
    "train_sequences = train_sequences[0:n_train]\n",
    "train_fitnesses = train_fitnesses[0:n_train]\n",
    "test_sequences = test_sequences[0:n_test]\n",
    "test_fitnesses = test_fitnesses[0:n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s:\\Documents\\master\\code\\llm\\lib\\model\\progen/../../../../../ProGen/progen/progen2/checkpoints/progen2-small were not used when initializing ProGenModel: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing ProGenModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ProGenModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model state dict from file \"s:\\Documents\\master\\code\\llm/models/progen_extended_data_filter_04.pt\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerExtended(\n",
       "  (transformer): ProGenModel(\n",
       "    (wte): Embedding(32, 1024)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): ProGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ProGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): ProGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (fitness_head): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (activation_function): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.model.extended.init_model import init_model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = init_model(state_dict_path=\"/models/progen_extended_data_filter_04.pt\").to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[208], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m ftinesses \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(sequences))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sequences)):\n\u001b[1;32m----> 3\u001b[0m     fitnesses[s] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m fitnesses\n",
      "File \u001b[1;32ms:\\Documents\\master\\code\\llm\\lib\\model\\extended\\TransformerExtended.py:25\u001b[0m, in \u001b[0;36mTransformerExtended.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     13\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     24\u001b[0m ):\n\u001b[1;32m---> 25\u001b[0m     transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     39\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness_head(hidden_states)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32ms:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32ms:\\Documents\\master\\code\\llm\\lib\\model\\progen/../../../../../ProGen\\progen\\progen2\\models\\progen\\modeling_progen.py:501\u001b[0m, in \u001b[0;36mProGenModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    493\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    494\u001b[0m         create_custom_forward(block),\n\u001b[0;32m    495\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m         head_mask[i],\n\u001b[0;32m    499\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 501\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32ms:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32ms:\\Documents\\master\\code\\llm\\lib\\model\\progen/../../../../../ProGen\\progen\\progen2\\models\\progen\\modeling_progen.py:263\u001b[0m, in \u001b[0;36mProGenBlock.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    261\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    262\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[1;32m--> 263\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[0;32m    272\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32ms:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32ms:\\Documents\\master\\code\\llm\\lib\\model\\progen/../../../../../ProGen\\progen\\progen2\\models\\progen\\modeling_progen.py:187\u001b[0m, in \u001b[0;36mProGenAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    185\u001b[0m sincos \u001b[38;5;241m=\u001b[39m fixed_pos_embedding(k_rot, \u001b[38;5;241m1\u001b[39m, seq_len\u001b[38;5;241m=\u001b[39mseq_len)\n\u001b[0;32m    186\u001b[0m k_rot \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(k_rot, sincos, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m--> 187\u001b[0m q_rot \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_rot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msincos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m key \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([k_rot, k_pass], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    190\u001b[0m query \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([q_rot, q_pass], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32ms:\\Documents\\master\\code\\llm\\lib\\model\\progen/../../../../../ProGen\\progen\\progen2\\models\\progen\\modeling_progen.py:55\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[1;34m(x, sincos, offset)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_rotary_pos_emb\u001b[39m(x, sincos, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 55\u001b[0m     sin, cos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: t[\u001b[38;5;28;01mNone\u001b[39;00m, offset : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m offset, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m), sincos)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# einsum notation for lambda t: repeat(t[offset:x.shape[1]+offset,:], \"n d -> () n () (d j)\", j=2)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_every_two(x) \u001b[38;5;241m*\u001b[39m sin)\n",
      "File \u001b[1;32ms:\\Documents\\master\\code\\llm\\lib\\model\\progen/../../../../../ProGen\\progen\\progen2\\models\\progen\\modeling_progen.py:55\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_rotary_pos_emb\u001b[39m(x, sincos, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 55\u001b[0m     sin, cos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m, sincos)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# einsum notation for lambda t: repeat(t[offset:x.shape[1]+offset,:], \"n d -> () n () (d j)\", j=2)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_every_two(x) \u001b[38;5;241m*\u001b[39m sin)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitnesses = torch.empty(len(sequences))\n",
    "for s in range(len(sequences)):\n",
    "    fitnesses[s] = model.forward(sequences[s])[-1]\n",
    "fitnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FWAA\n"
     ]
    }
   ],
   "source": [
    "decode = lambda id: tokenizer.id_to_token(id)\n",
    "\n",
    "\n",
    "def extract_token(seq, idx, decode):\n",
    "    return decode(int(seq[idx]))\n",
    "\n",
    "\n",
    "seq = sequences[57022]\n",
    "print(\n",
    "    extract_token(seq, 38, decode)\n",
    "    + extract_token(seq, 39, decode)\n",
    "    + extract_token(seq, 40, decode)\n",
    "    + extract_token(seq, 53, decode)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0786], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 127726; SQMA; 0,0140767875885\n",
    "# 57022; FWAA; 8,76196565571\n",
    "out = model.forward(sequences[127726])\n",
    "out.size()\n",
    "out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0783], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.forward(sequences[57022])\n",
    "out.size()\n",
    "out[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train(\n",
    "    model=model,\n",
    "    device=device,\n",
    "\n",
    "    train_data=train_sequences,\n",
    "    train_labels=train_fitnesses,\n",
    "    test_data=test_sequences,\n",
    "    test_labels=test_fitnesses,\n",
    "\n",
    "    loss_function=torch.nn.functional.mse_loss,\n",
    "    batch_size=1,\n",
    "    learning_rate=1e-3,\n",
    "    n_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Progen Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from progen_extended import train_progen_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train_progen_extended(\n",
    "    state_dict_path=\"\",\n",
    "    save_state_dict=\"/models/progen_extended_tmp2.pt\",\n",
    "    save_history=\"/models/progen_extended_tmp2_history.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_history = torch.load(\"./models/progen_extended_data_balanced_01_info.pt\")[\"loss_history\"]\n",
    "#loss_history = torch.load(\"./models/progen_extended_v1_01_history.pt\")\n",
    "loss_history = torch.load(\"./models/progen_extended_data_filter_01_history.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 10])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6872)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(0, loss_history[0, -1], '.')\n",
    "for i in range(1, loss_history.size()[0]):\n",
    "    plt.plot(\n",
    "        [(i-1)*loss_history.size()[1]+b for b in range(1, loss_history.size()[1]+1)],\n",
    "        #torch.cat((loss_history[0, -1:], loss_history[1, :])),\n",
    "        loss_history[i, :],\n",
    "        \".-\",\n",
    "    )\n",
    "plt.xlabel(\"Evaluation #\")\n",
    "plt.ylabel(\"Error on test data\")\n",
    "plt.title(\"Progen extended training\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_function': <function torch.nn.functional.l1_loss(input: torch.Tensor, target: torch.Tensor, size_average: Union[bool, NoneType] = None, reduce: Union[bool, NoneType] = None, reduction: str = 'mean') -> torch.Tensor>,\n",
       " 'learning_rate': 0.001,\n",
       " 'batch_size': 100,\n",
       " 'n_epochs': 1,\n",
       " 'evaluation_period': 1}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tp = torch.load(\"./models/progen_extended_data_balanced_01_info.pt\")\n",
    "#tp = torch.load(\"./models/progen_extended_v1_01_train_params.pt\")\n",
    "tp = torch.load(\"./models/progen_extended_data_filter_05_train_params.pt\")\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from progen_extended_init_test import test_initialization\n",
    "from lib.utils.file import save_pt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to device\n",
      "Loading tokenizer\n",
      "Loading GB1 data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s:\\Documents\\master\\code\\llm\\lib\\model\\progen/../../../../../ProGen/progen/progen2/checkpoints/progen2-small were not used when initializing ProGenModel: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing ProGenModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ProGenModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running initialization test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Documents\\master\\code\\llm\\progen_extended_init_test.py:51: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  losses[init] = loss_function(outputs, fitnesses)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 1: loss = 3.0504567623138428\n",
      "Initialization 2: loss = 8.231841087341309\n",
      "Initialization 3: loss = 6.611791133880615\n",
      "Initialization 4: loss = 3.734952449798584\n",
      "Initialization 5: loss = 7.981017112731934\n",
      "Initialization 6: loss = 8.263606071472168\n",
      "Initialization 7: loss = 5.743655681610107\n",
      "Initialization 8: loss = 3.9771087169647217\n",
      "Initialization 9: loss = 3.639610767364502\n",
      "Initialization 10: loss = 8.420339584350586\n",
      "Initialization 11: loss = 8.270730972290039\n",
      "Initialization 12: loss = 5.089890003204346\n",
      "Initialization 13: loss = 4.61594295501709\n",
      "Initialization 14: loss = 8.41986083984375\n",
      "Initialization 15: loss = 7.164413928985596\n",
      "Initialization 16: loss = 8.370397567749023\n",
      "Initialization 17: loss = 8.238313674926758\n",
      "Initialization 18: loss = 7.744263172149658\n",
      "Initialization 19: loss = 3.364473342895508\n",
      "Initialization 20: loss = 8.223790168762207\n",
      "Initialization 21: loss = 5.46920108795166\n",
      "Initialization 22: loss = 10.152097702026367\n",
      "Initialization 23: loss = 7.843621730804443\n",
      "Initialization 24: loss = 8.072525978088379\n",
      "Initialization 25: loss = 4.287817478179932\n",
      "Initialization 26: loss = 6.1101155281066895\n",
      "Initialization 27: loss = 7.631990909576416\n",
      "Initialization 28: loss = 7.288402557373047\n",
      "Initialization 29: loss = 6.593654155731201\n",
      "Initialization 30: loss = 8.317606925964355\n",
      "Initialization 31: loss = 8.302433013916016\n",
      "Initialization 32: loss = 3.5913357734680176\n",
      "Initialization 33: loss = 8.319964408874512\n",
      "Initialization 34: loss = 5.866611480712891\n",
      "Initialization 35: loss = 6.968106746673584\n",
      "Initialization 36: loss = 8.229589462280273\n",
      "Initialization 37: loss = 8.291772842407227\n",
      "Initialization 38: loss = 4.557093143463135\n",
      "Initialization 39: loss = 8.356832504272461\n",
      "Initialization 40: loss = 8.357412338256836\n",
      "Initialization 41: loss = 8.34814453125\n",
      "Initialization 42: loss = 8.341302871704102\n",
      "Initialization 43: loss = 5.89824914932251\n",
      "Initialization 44: loss = 5.019021034240723\n",
      "Initialization 45: loss = 8.010868072509766\n",
      "Initialization 46: loss = 8.376656532287598\n",
      "Initialization 47: loss = 7.4564900398254395\n",
      "Initialization 48: loss = 4.514138698577881\n",
      "Initialization 49: loss = 8.28763198852539\n",
      "Initialization 50: loss = 5.112214088439941\n",
      "Initialization 51: loss = 4.437225818634033\n",
      "Initialization 52: loss = 12.785075187683105\n",
      "Initialization 53: loss = 8.290003776550293\n",
      "Initialization 54: loss = 8.241737365722656\n",
      "Initialization 55: loss = 8.369268417358398\n",
      "Initialization 56: loss = 8.499056816101074\n",
      "Initialization 57: loss = 8.356027603149414\n",
      "Initialization 58: loss = 8.285224914550781\n",
      "Initialization 59: loss = 3.97176194190979\n",
      "Initialization 60: loss = 3.2592177391052246\n",
      "Initialization 61: loss = 3.5881333351135254\n",
      "Initialization 62: loss = 8.27623462677002\n",
      "Initialization 63: loss = 8.037960052490234\n",
      "Initialization 64: loss = 3.2904655933380127\n",
      "Initialization 65: loss = 3.395535707473755\n",
      "Initialization 66: loss = 7.611125946044922\n",
      "Initialization 67: loss = 8.1759672164917\n",
      "Initialization 68: loss = 3.3004958629608154\n",
      "Initialization 69: loss = 8.231853485107422\n",
      "Initialization 70: loss = 8.390228271484375\n",
      "Initialization 71: loss = 4.0346598625183105\n",
      "Initialization 72: loss = 8.242217063903809\n",
      "Initialization 73: loss = 6.172999382019043\n",
      "Initialization 74: loss = 6.950654029846191\n",
      "Initialization 75: loss = 3.2557177543640137\n",
      "Initialization 76: loss = 3.7144935131073\n",
      "Initialization 77: loss = 4.272558689117432\n",
      "Initialization 78: loss = 8.35381031036377\n",
      "Initialization 79: loss = 6.436473846435547\n",
      "Initialization 80: loss = 6.676143169403076\n",
      "Initialization 81: loss = 7.954300880432129\n",
      "Initialization 82: loss = 8.561423301696777\n",
      "Initialization 83: loss = 3.7950351238250732\n",
      "Initialization 84: loss = 8.336440086364746\n",
      "Initialization 85: loss = 5.582737445831299\n",
      "Initialization 86: loss = 8.483521461486816\n",
      "Initialization 87: loss = 8.311736106872559\n",
      "Initialization 88: loss = 8.054645538330078\n",
      "Initialization 89: loss = 8.31817626953125\n",
      "Initialization 90: loss = 8.287738800048828\n",
      "Initialization 91: loss = 3.5578877925872803\n",
      "Initialization 92: loss = 11.599794387817383\n",
      "Initialization 93: loss = 6.6636552810668945\n",
      "Initialization 94: loss = 8.4664306640625\n",
      "Initialization 95: loss = 8.296904563903809\n",
      "Initialization 96: loss = 8.231406211853027\n",
      "Initialization 97: loss = 5.580757141113281\n",
      "Initialization 98: loss = 8.182802200317383\n",
      "Initialization 99: loss = 7.132348537445068\n",
      "Initialization 100: loss = 8.229118347167969\n",
      "saving losses and data to file \"s:\\Documents\\master\\code\\llm/data/init_test_ninit-100_data-select_lf-mse_run-1.pt\"\n"
     ]
    }
   ],
   "source": [
    "N_INITIALIZATIONS = 100\n",
    "\n",
    "DATA_INDEXES = [0, 1, 18, 74, 519, 623, 949, 32322, 50456, 49771]\n",
    "N_DATA = None\n",
    "#N_DATA = 100\n",
    "\n",
    "LOSS_FUNCTION = torch.nn.functional.mse_loss\n",
    "LOSS_FUNCTION_NAME = \"mse\"\n",
    "RUN = 1\n",
    "\n",
    "losses, sequences, fitnesses = test_initialization(\n",
    "    n_initializations=N_INITIALIZATIONS,\n",
    "    n_data=N_DATA,\n",
    "    data_indexes=DATA_INDEXES,\n",
    "    loss_function=LOSS_FUNCTION,\n",
    "    return_data=True,\n",
    ")\n",
    "\n",
    "save_pt_file(\n",
    "    {\"losses\": losses, \"sequences\": sequences, \"fitnesses\": fitnesses},\n",
    "    #save_to=f\"/data/init_test_ninit-{N_INITIALIZATIONS}_ndata-{N_DATA}_lf-{LOSS_FUNCTION_NAME}_run-{RUN}.pt\",\n",
    "    save_to=f\"/data/init_test_ninit-{N_INITIALIZATIONS}_data-select_lf-{LOSS_FUNCTION_NAME}_run-{RUN}.pt\",\n",
    "    var_name=\"losses and data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.0619, 2.4012, 3.8915, 0.0000, 5.0753, 0.6749, 2.0556, 3.6573,\n",
       "        4.0796], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Documents\\master\\ProGen\\progen\\progen2\\.venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    sequences,\n",
    "    fitnesses,\n",
    ") = get_GB1_dataset(shuffle=False, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = 'AACAACAACAAACAACAACAAACAACAACAAACAACAACAAACAACAACAAACAACAACAAACAACAACAAACAACAACAAACAACAACAAACAACAACA'\n",
    "#sequence = 'CCACCACCACCCACCACCACCCACCACCACCCACCACCACCCACCACCACCCACCACCACCCACCACCACCCACCACCACCCACCACCACCCACCACCAC'\n",
    "sequence.count('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(tokenize(sequence).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 83.6339],\n",
       "        [ 83.6339],\n",
       "        [ 97.4809],\n",
       "        [100.6896],\n",
       "        [ 88.4701],\n",
       "        [ 87.8587],\n",
       "        [ 85.4522],\n",
       "        [ 72.6343],\n",
       "        [ 84.1265],\n",
       "        [ 79.6446],\n",
       "        [ 58.5573],\n",
       "        [ 78.8447],\n",
       "        [ 92.9054],\n",
       "        [ 79.2548],\n",
       "        [ 79.8149],\n",
       "        [ 80.9938],\n",
       "        [ 80.0447],\n",
       "        [ 64.2967],\n",
       "        [ 79.4195],\n",
       "        [ 80.0127],\n",
       "        [ 64.9874],\n",
       "        [ 76.4079],\n",
       "        [ 86.0560],\n",
       "        [ 80.3433],\n",
       "        [ 62.1999],\n",
       "        [ 79.2397],\n",
       "        [ 80.3691],\n",
       "        [ 62.5652],\n",
       "        [ 79.0061],\n",
       "        [ 79.3325],\n",
       "        [ 62.2452],\n",
       "        [ 69.8980],\n",
       "        [ 84.3062],\n",
       "        [ 77.7817],\n",
       "        [ 61.2099],\n",
       "        [ 76.6757],\n",
       "        [ 79.0464],\n",
       "        [ 61.9562],\n",
       "        [ 76.4405],\n",
       "        [ 77.5661],\n",
       "        [ 62.6651],\n",
       "        [ 64.0236],\n",
       "        [ 82.6489],\n",
       "        [ 76.2479],\n",
       "        [ 59.7201],\n",
       "        [ 75.7414],\n",
       "        [ 77.9078],\n",
       "        [ 61.8727],\n",
       "        [ 75.0160],\n",
       "        [ 76.1137],\n",
       "        [ 62.6268],\n",
       "        [ 60.2531],\n",
       "        [ 81.1289],\n",
       "        [ 74.9762],\n",
       "        [ 58.1969],\n",
       "        [ 75.1176],\n",
       "        [ 76.5523],\n",
       "        [ 61.5985],\n",
       "        [ 74.2997],\n",
       "        [ 75.4098],\n",
       "        [ 62.4471],\n",
       "        [ 57.3564],\n",
       "        [ 79.7718],\n",
       "        [ 75.1304],\n",
       "        [ 57.2749],\n",
       "        [ 75.0074],\n",
       "        [ 75.9496],\n",
       "        [ 60.9523],\n",
       "        [ 73.8720],\n",
       "        [ 74.6914],\n",
       "        [ 62.5417],\n",
       "        [ 55.7798],\n",
       "        [ 78.5093],\n",
       "        [ 74.3840],\n",
       "        [ 57.0368],\n",
       "        [ 74.8045],\n",
       "        [ 75.1717],\n",
       "        [ 61.1564],\n",
       "        [ 73.7972],\n",
       "        [ 73.8871],\n",
       "        [ 62.5341],\n",
       "        [ 54.2392],\n",
       "        [ 78.1669],\n",
       "        [ 73.9486],\n",
       "        [ 55.9068],\n",
       "        [ 74.3266],\n",
       "        [ 74.2970],\n",
       "        [ 60.0592],\n",
       "        [ 73.1964],\n",
       "        [ 73.3230],\n",
       "        [ 62.1923],\n",
       "        [ 53.1949],\n",
       "        [ 77.0651],\n",
       "        [ 73.6418],\n",
       "        [ 55.2260],\n",
       "        [ 73.4659],\n",
       "        [ 73.5770],\n",
       "        [ 59.7116],\n",
       "        [ 72.3021],\n",
       "        [ 72.6306]], device='cuda:0', grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
